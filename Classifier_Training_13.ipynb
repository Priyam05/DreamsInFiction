{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "1. Lower case tokens DONE\n",
    "2. Reevaluate 200 to 600 -- DONE....Testing\n",
    "3. Normalise both dream and fiction to a constant value. Keep the tokens after groupby HALF DONE ....DONE...Testing\n",
    "<br/> **Issues**: \n",
    "    - Check if stopwords have punctuations coz punctuation feature has zero counts. DONE \n",
    "      - Punctuation was being removed in the stop word filter function, fixed so that it is included.\n",
    "    - Suggestion: Add count filter for both dream and fiction?? DONE\n",
    "    - Normalise based on averge count(instead of max_val) and then normalise to a constant val and add a min-max bound DONE \n",
    "      - Edited rescale and get_data to include new constant parameter which specifies if we are using 'avg' or 'max' for normalization\n",
    "\n",
    "4. Try other algorithms only if Logistic works well -- DONE \n",
    "Need a fix for using Naive Bayes, Random Forest, etc -- Link: https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required\n",
    "5. Add in POS as a feature -- DONE\n",
    "<br/>**Issue**:\n",
    "        -Check if Stopword is removing second and third person pronouns like 'he', 'she', 'they'. Coz there are no third person feature in Pronoun and hardly any second person. -- DONE\n",
    "        -Should we normalise count values again in the feature function?? Removing it tends to give better accuracy -- NOT REQUIRED\n",
    "6. Look into dream set overfitting, in particular brackets, parantheses, and certain proper names. DONE\n",
    "<br/> **Issue**: I still see 'ezra' in the unigram feature \n",
    "7. Incorporate validation set DONE\n",
    "8. Test with Confidence Intervals HALF DONE\n",
    "    - We should repeat this process on different samples of 100 books DONE\n",
    "        - Edited get_fictional_data to select random samples from Hathi DONE\n",
    "        - We should maybe brainstorm how to bootstrap and then conduct a bootstrap CI test? **CAN STILL DO THIS**\n",
    "    - As well as incorporate fiction pages into the validation set for testing contrast\n",
    "        - Need a better way to access pages to do so, but also is this necessary? I feel like just using the fictional dreams is fine\n",
    "9. Merge all features into single model DONE\n",
    "10. Find out why final model is overfitting, add more fictional dreams to the validation dataset HALF DONE\n",
    "    - Added more fictional dreams, not sure why model is overfitting.\n",
    "11. Mix & Match Features & models to check if validation accuracy improves --- **IMPORTANT**\n",
    "    - SVC is promising, gets to around 70-80%. Only issue is that we need a hold out set for fiction data, as a book having already been seen is probably causing higher results DONE\n",
    "    - Still could mix and match features\n",
    "12. Check precision, recall, and F1 as well\n",
    "13. Figure out latex statistics for report\n",
    "14. Finish off validation set with Akhilesh's dreams and some more from Hathi, goal ~80 dreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/abc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/abc/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from scipy import sparse\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from htrc_features import FeatureReader, Volume\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_data = pickle.load(open('dreamsDF.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename chunk in dream_data as page\n",
    "dream_data = dream_data.rename(columns={\"chunk\" : \"page\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords(filename):\n",
    "    stopwords={}\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            stopwords[line.rstrip()]=1\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "jockers_list = read_stopwords(\"../data/jockers.stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnouns_set=set()\n",
    "with open(\"pronoun.txt\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        cols=line.rstrip().split(\"\\t\")\n",
    "        pnouns_set.add(cols[0])\n",
    "\n",
    "final_stopword_set = set(stopwords.words('english')) - pnouns_set\n",
    "stop_words = {k:1 for k in final_stopword_set}\n",
    "# stop_words.update(read_stopwords(\"../data/jockers.stopwords\"))\n",
    "stop_words[\"dream\"]=1\n",
    "stop_words[\"dreams\"]=1\n",
    "stop_words[\"dreamer\"]=1\n",
    "stop_words['dreamt']=1\n",
    "stop_words['dreamed']=1\n",
    "stop_words[\"awake\"]=1\n",
    "stop_words[\"awaken\"]=1\n",
    "stop_words['awoke']=1\n",
    "stop_words['sleep']=1\n",
    "stop_words['-rrb-']=1\n",
    "stop_words['-lrb-']=1\n",
    "stop_words['-lsb-']=1\n",
    "stop_words['-rsb-']=1\n",
    "stop_words['nan']=1\n",
    "stop_words['`']=1\n",
    "stop_words[']']=1\n",
    "keys_copy = list(stop_words.keys())\n",
    "for i in keys_copy:\n",
    "    key = \"'\"+i\n",
    "    stop_words[key]=1\n",
    "stop_words=list(stop_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_filter(word, stopwords):\n",
    "    \n",
    "    \"\"\" Function to exclude words from a text \"\"\"\n",
    "    \n",
    "    # no stopwords\n",
    "    if word in stopwords:\n",
    "        return False\n",
    "    \n",
    "    #has to contain at least one letter or valid punctuation\n",
    "    if re.search(\"[a-zA-Z]\", word) is not None or re.search('[.!,\"`\\|:;?\\/\\\\\\-{}\\']', word) is not None:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the average number of tokens in each page of dream and fiction after removing the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_filter(\"'re\", stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>tokens</th>\n",
       "      <th>counts</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [page, tokens, counts, pos]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_data = dream_data.loc[[stop_filter(x, stop_words) for x in dream_data['tokens']]] #Also added to the get_data() function\n",
    "dream_data[dream_data['tokens']==\"'re\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "counts    121.002657\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_data.groupby('page').sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3eaa2832690b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HathiTrust/fiction\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/*bz2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_vols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtotal_books\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_vols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolumes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/htrc_features/feature_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ids, paths, dir, format, id_resolver, compression, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# only one of paths or ids can be selected - otherwise it's not clear what to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paths = glob.glob(\"HathiTrust/fiction\"+\"/*bz2\", recursive=True)\n",
    "all_vols = FeatureReader(paths)\n",
    "total_books=0\n",
    "means=[]\n",
    "for vol in tqdm(all_vols.volumes()): \n",
    "    if(total_books==1):\n",
    "        break\n",
    "    total_books+=1\n",
    "    df = vol.tokenlist().reset_index()\n",
    "    df.rename(columns={\"token\":\"tokens\", \"count\" : \"counts\"}, inplace=True)\n",
    "    df[\"tokens\"]= df[\"tokens\"].str.lower()\n",
    "    df = df.loc[[stop_filter(x, stop_words) for x in df['tokens']]]\n",
    "    means.append(df.groupby('page').sum().mean())\n",
    "\n",
    "sum(means)/len(means)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that average token counts per page in dream is ~76 and in fiction is ~157. However, there is a huge variance in their max and min\n",
    "#### Now we need to implement two steps based on this average count\n",
    "1. Rescale both dream and fiction to 200\n",
    "2. Remove all the fiction pages which are less than 50 after rescaling. Should we also remove dream ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>tokens</th>\n",
       "      <th>counts</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>my</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>10.0</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>thing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478087</th>\n",
       "      <td>26342</td>\n",
       "      <td>celine</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478088</th>\n",
       "      <td>26342</td>\n",
       "      <td>dion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478089</th>\n",
       "      <td>26342</td>\n",
       "      <td>sprinkle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478090</th>\n",
       "      <td>26342</td>\n",
       "      <td>oceanside</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478091</th>\n",
       "      <td>26342</td>\n",
       "      <td>transient</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1772430 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          page     tokens  counts   pos\n",
       "1            0         my     4.0  PRP$\n",
       "3            0          ,    10.0     ,\n",
       "5            0      first     1.0    RB\n",
       "6            0      thing     1.0    NN\n",
       "7            0          i    12.0    NN\n",
       "...        ...        ...     ...   ...\n",
       "2478087  26342     celine     2.0    NN\n",
       "2478088  26342       dion     1.0    NN\n",
       "2478089  26342   sprinkle     1.0    NN\n",
       "2478090  26342  oceanside     1.0    NN\n",
       "2478091  26342  transient     1.0    NN\n",
       "\n",
       "[1772430 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dream Bank data ## DO NOT RUN\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/josauder/dreambank_visualized/master/dreams.csv\")\n",
    "\n",
    "data.to_csv(\"DreamBank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaleCounts(df, rescale_val, constant):\n",
    "    if constant == 'max':\n",
    "        grouped_df = df.groupby('page')\n",
    "\n",
    "        #Get max token count page in the df......We are rescaling based on max counts in the book. We can also use average and have max and min bounds while filtering out\n",
    "        max_val = grouped_df.sum().max()['counts']\n",
    "\n",
    "        df_new = grouped_df.apply(lambda x: x['counts']*rescale_val/max_val).reset_index().drop(columns='level_1')\n",
    "        \n",
    "    if constant == 'avg':\n",
    "        grouped_df = df.groupby('page')\n",
    "\n",
    "        #Get max token count page in the df......We are rescaling based on max counts in the book. We can also use average and have max and min bounds while filtering out\n",
    "        avg_val = grouped_df.sum().mean()['counts']\n",
    "\n",
    "        df_new = grouped_df.apply(lambda x: x['counts']*rescale_val/ avg_val).reset_index().drop(columns='level_1')\n",
    "        \n",
    "    df_new['tokens'] = df['tokens']\n",
    "    df_new['pos'] = df['pos']\n",
    "    df_new.dropna(inplace=True)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, label, constant):\n",
    "    data=[]\n",
    "    #Filter out the stop_words\n",
    "    df = df.loc[[stop_filter(x, stop_words) for x in df['tokens']]]\n",
    "    #Rescale all the tokens to 200\n",
    "    df = rescaleCounts(df, 200, 'max')\n",
    "    df['combined']=df['tokens']+'#_'+df['pos']\n",
    "    ##Create list of feats and label \n",
    "    page_list = df.page.unique()\n",
    "    for page_val in page_list:\n",
    "        df_filtered = df[df['page']==page_val]\n",
    "        \n",
    "        #Filter out page with less than 50 tokens even after rescaling. Should we add this condition for both fiction and dream????\n",
    "        if constant == 'max':\n",
    "            if (label==0) and (sum(df_filtered['counts']) < 50):\n",
    "                continue\n",
    "            if (label==1) and (sum(df_filtered['counts']) < 0.55):\n",
    "                continue\n",
    "        \n",
    "        #Estimated upper and lower bounds when using average count to normalize (fiction could use some more investigation)\n",
    "        if constant == 'avg':\n",
    "            if (label==0) and (sum(df_filtered['counts']) > 300) and (sum(df_filtered['counts']) < 30):\n",
    "                continue\n",
    "            if (label==1) and (sum(df_filtered['counts']) > 300) and (sum(df_filtered['counts']) < 30):\n",
    "                continue\n",
    "                \n",
    "        feats= dict(zip(df_filtered['combined'], df_filtered['counts']))\n",
    "        data.append((feats,label))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get fiction data volume\n",
    "def get_fiction_data(data, fict_folder, total_books, train_test='train'):\n",
    "    #Get all the volumes\n",
    "\n",
    "    paths = glob.glob(fict_folder+\"/*bz2\", recursive=True)\n",
    "    if train_test == 'train':\n",
    "        paths = paths[:400] #leaving hold out for test\n",
    "    if train_test == 'test':\n",
    "        paths = paths[:-100] #possible volumes for the validation set\n",
    "    random.shuffle(paths)\n",
    "    all_vols = FeatureReader(paths)\n",
    "    \n",
    "    books=0\n",
    "    for vol in tqdm(all_vols.volumes()): \n",
    "        if(total_books==books):\n",
    "            break\n",
    "        books+=1\n",
    "        df = vol.tokenlist().reset_index()\n",
    "        df.rename(columns={\"token\":\"tokens\", \"count\" : \"counts\"}, inplace=True)\n",
    "        \n",
    "        df[\"tokens\"]= df[\"tokens\"].str.lower()\n",
    "\n",
    "        the_list=get_data(df, 0, 'avg')\n",
    "        data.extend(the_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data():\n",
    "    data=[]\n",
    "    fict_folder= \"/home/abc/Berkeley/CompHum/Project/HathiTrust/fiction\"\n",
    "    get_fiction_data(data, fict_folder, 200) #Get 200 books\n",
    "    data.extend(get_data(dream_data, 1, 'max'))\n",
    "    #data.extend(get_data(fiction_data,0))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for unigram_counts, label in data:\n",
    "        X.append(unigram_counts)\n",
    "        Y.append(label)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [03:10,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "X, Y=get_all_data()\n",
    "trainX, devX, trainY, devY = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19934 43208 5095 10691\n"
     ]
    }
   ],
   "source": [
    "print(trainY.count(1), trainY.count(0), devY.count(1), devY.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(dataX, feature_functions):\n",
    "    \n",
    "    \"\"\" This function featurizes the data according to the list of parameter feature_functions \"\"\"\n",
    "    \n",
    "    data=[]\n",
    "    for tokens in dataX:\n",
    "        feats={}\n",
    "        \n",
    "        for function in feature_functions:\n",
    "            feats.update(function(tokens))\n",
    "\n",
    "        data.append(feats)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_to_ids(data, feature_vocab):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    This helper function converts a dictionary of feature names to a sparse representation\n",
    " that we can fit in a scikit-learn model.  This is important because almost all feature \n",
    " values will be 0 for most documents (note: why?), and we don't want to save them all in \n",
    " memory.\n",
    "\n",
    "    \"\"\"\n",
    "    new_data=sparse.lil_matrix((len(data), len(feature_vocab)))\n",
    "    for idx,doc in enumerate(data):\n",
    "        for f in doc:\n",
    "            if f in feature_vocab:\n",
    "                new_data[idx,feature_vocab[f]]=doc[f]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(data, top_n=None):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    This helper function converts a dictionary of feature names to unique numerical ids. \n",
    "    top_n limits the features to only the n most frequent features observed in the training data \n",
    "    (in terms of the number of documents that contains it).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    counts=Counter()\n",
    "    for doc in data:\n",
    "        for feat in doc:\n",
    "            counts[feat]+=1\n",
    "\n",
    "    feature_vocab={}\n",
    "\n",
    "    for idx, (k, v) in enumerate(counts.most_common(top_n)):\n",
    "        feature_vocab[k]=idx\n",
    "                \n",
    "    return feature_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(trainX, devX, trainY, devY, feature_functions, clf):\n",
    "\n",
    "    \"\"\" This function evaluates a list of feature functions on the training/dev data arguments \"\"\"\n",
    "    \n",
    "    trainX_feat=build_features(trainX, feature_functions)\n",
    "    devX_feat=build_features(devX, feature_functions)\n",
    "\n",
    "    # just create vocabulary from features in *training* data.\n",
    "    feature_vocab=create_vocab(trainX_feat, top_n=1000)\n",
    "\n",
    "    trainX_ids=features_to_ids(trainX_feat, feature_vocab)\n",
    "    devX_ids=features_to_ids(devX_feat, feature_vocab)\n",
    "    \n",
    "    ## TO DO: We should build more models with different ML algorithms\n",
    "#     clf = linear_model.LogisticRegression(C=100, solver='lbfgs', penalty='l2', max_iter=10000) #Works#Ridge regression\n",
    "    #clf = linear_model.Perceptron(tol=1e-3, random_state=0) #Works\n",
    "    #clf=linear_model.LogisticRegression(C=10,penalty='l1', tol=0.01, solver='saga') #Lasso Regression\n",
    "    #clf = GaussianNB() #Gives error as it needs dense array. Check link: https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required\n",
    "    #clf=linear_model.BayesianRidge() #Takes too long to run\n",
    "    #clf= LinearSVC() #Works#Linear Support Vector Classification. Works for both sparse and dense data\n",
    "    #clf=SVR() #Takes forever to run\n",
    "    #clf = MultinomialNB() #Works\n",
    "    #clf = BernoulliNB() #Works\n",
    "#     clf = RandomForestClassifier(max_depth=2, random_state=0) #Works\n",
    "    clf.fit(trainX_ids, trainY)\n",
    "    print(\"Accuracy: %.3f\" % clf.score(devX_ids, devY))\n",
    "    print(\"F1-score:\", f1_score(devY, clf.predict(devX_ids)))\n",
    "    \n",
    "    return clf, feature_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(clf, vocab, n=10, model=None):\n",
    "    if(model=='RF'):\n",
    "        weights = clf.feature_importances_\n",
    "    else:\n",
    "        weights=clf.coef_[0]\n",
    "    reverse_vocab=[None]*len(weights)\n",
    "    for k in vocab:\n",
    "        reverse_vocab[vocab[k]]=k\n",
    "\n",
    "    for feature, weight in sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))[:n]:\n",
    "        print(\"%.3f\\t%s\" % (weight, feature))\n",
    "\n",
    "    print()\n",
    "\n",
    "    for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "        print(\"%.3f\\t%s\" % (weight, feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_feature(unigram_counts):\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    See 2.classification/Classification.ipynb for an example feature function to get started.\n",
    "    This function should return a dictionary with feature names as keys as feature values as values, e.g.:\n",
    "    {\"unigram_the\": 0.04, \"unigram_fiction\": 0.001, ...}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    feats={}\n",
    "    total = 0\n",
    "    # your code goes here\n",
    "    \n",
    "    #unigram_counts has count of each word. We first calculate the total number of words\n",
    "    for word in unigram_counts:\n",
    "        total+= unigram_counts[word]\n",
    "        \n",
    "    #Now we calculate the frequency\n",
    "    \n",
    "    for word in unigram_counts:\n",
    "        word_token = str(word).split('#_')[0]\n",
    "        feats[\"unigram_\"+str(word_token)] = unigram_counts[word]/total\n",
    "           \n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_feature(unigram_counts): ####TO BE IMPLEMENTED\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    See 2.classification/Classification.ipynb for an example feature function to get started.\n",
    "    This function should return a dictionary with feature names as keys as feature values as values, e.g.:\n",
    "    {\"unigram_the\": 0.04, \"unigram_fiction\": 0.001, ...}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    feats={}\n",
    "    total = 0\n",
    "    # your code goes here\n",
    "    \n",
    "    #unigram_counts has count of each word. We first calculate the total number of words\n",
    "    for word in unigram_counts:\n",
    "        total+= unigram_counts[word]\n",
    "        \n",
    "    #Now we calculate the frequency\n",
    "    \n",
    "    for word in unigram_counts:\n",
    "        word_pos = str(word).split('#_')[1]\n",
    "        if(\"pos_\"+str(word_pos) in feats):\n",
    "            feats[\"pos_\"+str(word_pos)] += unigram_counts[word]/total\n",
    "        else:\n",
    "            feats[\"pos_\"+str(word_pos)] = unigram_counts[word]/total\n",
    "           \n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc={}\n",
    "with open(\"liwc.dictionary.txt\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        cols=line.rstrip().split(\"\\t\")\n",
    "        word=cols[0]\n",
    "        liwcs=cols[1].split(\" \")\n",
    "        liwc[word]=liwcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liwc_feature(unigram_counts):\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    See 2.classification/Classification.ipynb for an example feature function to get started.\n",
    "    This function should return a dictionary with feature names as keys as feature values as values, e.g.:\n",
    "    {\"liwc_percept\": 0.04, \"liwc_affect\": 0.05, ...}\n",
    "    \n",
    "    \"\"\"\n",
    "                \n",
    "    feats={}\n",
    "\n",
    "\n",
    "    # your code goes here\n",
    "    counts=Counter()\n",
    "    total=0.\n",
    "    for word in unigram_counts:\n",
    "        word_token = str(word).split('#_')[0] \n",
    "        if word_token in liwc:\n",
    "            for l in liwc[word_token]:\n",
    "                counts[l]+=unigram_counts[word]\n",
    "                total+=unigram_counts[word]\n",
    "    \n",
    "    for l in counts:\n",
    "        feats[\"liwc_\"+str(l)]=float(counts[l])/total\n",
    "    \n",
    "    #print(feats)\n",
    "    return feats\n",
    "#     return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnouns={}\n",
    "with open(\"pronoun.txt\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        cols=line.rstrip().split(\"\\t\")\n",
    "        #print(cols)\n",
    "        word=cols[0]\n",
    "        pnoun=cols[1].split(\" \")\n",
    "        pnouns[word]=pnoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronoun_feature(unigram_counts):\n",
    "    feats={}\n",
    "\n",
    "\n",
    "    # your code goes here\n",
    "    counts=Counter()\n",
    "    total=0.\n",
    "    for word in unigram_counts:\n",
    "        word_token = str(word).split('#_')[0].lower()\n",
    "        if word_token in pnouns:\n",
    "            for l in pnouns[word_token]:\n",
    "                counts[l]+=unigram_counts[word]\n",
    "                total+=unigram_counts[word]\n",
    "    \n",
    "    for l in counts:\n",
    "        feats['pnoun'+str(l)]=float(counts[l])/total\n",
    "    #print(feats)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##???? Are losing all the punctuations in the stopword filter?? No feature found here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_feature(tokens):\n",
    "    puncts=[\".\",\"!\",\",\",'\"',\"`\",\"'\" ,\"|\", \":\",\";\",\"?\",\"/\", \"\\\\\",\"-\", \"{\",\"}\",\"[\",\"]\",\"(\",\")\", \"...\" ] \n",
    "    feats={}\n",
    "\n",
    "\n",
    "    # your code goes here\n",
    "    counts=Counter()\n",
    "    total=0.\n",
    "    for word in tokens:\n",
    "        word_token =str(word).split('#_')[0].lower()\n",
    "        if word_token in puncts:\n",
    "            counts[word_token]+=1\n",
    "            total+=1\n",
    "    \n",
    "    for l in counts:\n",
    "        feats['punct'+str(l)]=float(counts[l])/total\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of words feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_length_feature(tokens):\n",
    "    max_len = len(\"pneumonoultramicroscopicsilicovolcanoconiosis\") #Longest known word length\n",
    "    puncts=[\".\",\"!\",\",\",'\"',\"`\",\"'\" ,\"|\", \":\",\";\",\"?\",\"/\", \"\\\\\",\"-\", \"{\",\"}\",\"[\",\"]\",\"(\",\")\", \"...\" ] \n",
    "    feats={}\n",
    "    # your code goes here\n",
    "    counts=Counter()\n",
    "    total=0.\n",
    "    for word in tokens:\n",
    "        word_token =str(word).split('#_')[0].lower()\n",
    "        if(word_token not in puncts and len(word_token)<= max_len):\n",
    "            word_len = len(word_token) \n",
    "            counts[word_len]+=1\n",
    "            total+=1\n",
    "            #print(word_token, word_len)\n",
    "    for l in counts:\n",
    "        feats['word_len'+str(l)]=float(counts[l])/total\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [06:29,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#Read Data\n",
    "X, Y=get_all_data()\n",
    "trainX, devX, trainY, devY = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19934 43208 5095 10691\n"
     ]
    }
   ],
   "source": [
    "print(trainY.count(1), trainY.count(0), devY.count(1), devY.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = linear_model.LogisticRegression(C=100, solver='lbfgs', penalty='l2', max_iter=10000) #Works#Ridge regression\n",
    "#clf = linear_model.Perceptron(tol=1e-3, random_state=0) #Works\n",
    "#clf=linear_model.LogisticRegression(C=10,penalty='l1', tol=0.01, solver='saga') #Lasso Regression\n",
    "#clf = GaussianNB() #Gives error as it needs dense array. Check link: https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required\n",
    "#clf=linear_model.BayesianRidge() #Takes too long to run\n",
    "#clf= LinearSVC(dual=False, max_iter=10000) #Works#Linear Support Vector Classification. Works for both sparse and dense data\n",
    "#clf=SVR() #Takes forever to run\n",
    "#clf = MultinomialNB() #Works\n",
    "#clf = BernoulliNB() #Works\n",
    "#clf = RandomForestClassifier(max_depth=2, random_state=0) #Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.986\n",
      "F1-score: 0.9780765857936276\n"
     ]
    }
   ],
   "source": [
    "#Train the model #We can change parameter n to see more dominant features in the list\n",
    "#features=[unigram_feature, pos_feature, liwc_feature, word_length_feature, punctuation_feature, pronoun_feature]\n",
    "features=[unigram_feature, pos_feature, liwc_feature]\n",
    "clf, vocab=pipeline(trainX, devX, trainY, devY, features, clf= RandomForestClassifier(max_depth=15, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000\tunigram_gently\n",
      "0.000\tunigram_learned\n",
      "0.000\tunigram_noise\n",
      "0.000\tunigram_crossed\n",
      "0.000\tunigram_bar\n",
      "0.000\tunigram_horse\n",
      "0.000\tunigram_repeated\n",
      "0.000\tunigram_send\n",
      "0.000\tunigram_quickly\n",
      "0.000\tunigram_loud\n",
      "0.000\tunigram_busy\n",
      "0.000\tunigram_paid\n",
      "0.000\tunigram_answered\n",
      "0.000\tunigram_forgotten\n",
      "0.000\tunigram_pleased\n",
      "0.000\tunigram_carry\n",
      "0.000\tunigram_finger\n",
      "0.000\tunigram_presence\n",
      "0.000\tunigram_laid\n",
      "0.000\tunigram_closer\n",
      "\n",
      "0.103\tpos_NNP\n",
      "0.060\tpos_VBP\n",
      "0.054\tpos_NN\n",
      "0.044\tpos_VBD\n",
      "0.025\tliwc_shehe\n",
      "0.023\tunigram_he\n",
      "0.021\tpos_JJ\n",
      "0.020\tliwc_certain\n",
      "0.018\tpos_:\n",
      "0.016\tpos_VB\n",
      "0.016\tliwc_you\n",
      "0.015\tliwc_auxverb\n",
      "0.014\tunigram_you\n",
      "0.014\tunigram_i\n",
      "0.014\tliwc_posemo\n",
      "0.014\tpos_UH\n",
      "0.013\tliwc_negemo\n",
      "0.013\tliwc_body\n",
      "0.013\tunigram_it\n",
      "0.012\tunigram_.\n"
     ]
    }
   ],
   "source": [
    "print_weights(clf, vocab, n=20, model='RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dream</td>\n",
       "      <td>0</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>I was in Italy, and awoke (or seemed to awake)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dream</td>\n",
       "      <td>1</td>\n",
       "      <td>The Idiot</td>\n",
       "      <td>Dostoevsky, Fyodor</td>\n",
       "      <td>I was in some room, not my own. It was a large...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dream</td>\n",
       "      <td>2</td>\n",
       "      <td>War and Peace</td>\n",
       "      <td>Tolstoy, Leo</td>\n",
       "      <td>I. A. Bazdei'ew is in my house and I want to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dream</td>\n",
       "      <td>3</td>\n",
       "      <td>War and Peace</td>\n",
       "      <td>Tolstoy, Leo</td>\n",
       "      <td>I saw as if in my house in Moscow, Bazdeiew en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dream</td>\n",
       "      <td>4</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>some English people had come into the hotel wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dream</td>\n",
       "      <td>5</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>It was a great Piazza, as I thought ; anchored...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dream</td>\n",
       "      <td>6</td>\n",
       "      <td>Rose o'the sea</td>\n",
       "      <td>Evans, Marguerite Florence Jervis Barclay</td>\n",
       "      <td>I was climbing great cliffs, like I used to at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dream</td>\n",
       "      <td>7</td>\n",
       "      <td>Nightshade</td>\n",
       "      <td>Gwynne, Paul</td>\n",
       "      <td>I remember vividly every detail of what I saw,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dream</td>\n",
       "      <td>8</td>\n",
       "      <td>Yonder</td>\n",
       "      <td>Young, E.H.</td>\n",
       "      <td>I was walking on a green path and I met a man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dream</td>\n",
       "      <td>9</td>\n",
       "      <td>Blind Eyes</td>\n",
       "      <td>Peterson, Margaret</td>\n",
       "      <td>Ted was dead, she fancied: his white, set face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dream</td>\n",
       "      <td>10</td>\n",
       "      <td>The White Causeway</td>\n",
       "      <td>Moore, F. Frankfort</td>\n",
       "      <td>I found myself wandering over a house , and lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dream</td>\n",
       "      <td>11</td>\n",
       "      <td>Dearlove : the history of her summer's makebel...</td>\n",
       "      <td>Campbell, Frances</td>\n",
       "      <td>we were standing on the shore, and your ship w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dream</td>\n",
       "      <td>12</td>\n",
       "      <td>For Charles the Rover</td>\n",
       "      <td>Knowles, Mabel Winifred</td>\n",
       "      <td>I thought myself once again a bride groom with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dream</td>\n",
       "      <td>13</td>\n",
       "      <td>Entrapped</td>\n",
       "      <td>Diehl, Alice M.</td>\n",
       "      <td>She was wandering in an English hayfield, unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dream</td>\n",
       "      <td>14</td>\n",
       "      <td>Uncle Polperro</td>\n",
       "      <td>Courlander, Alphonse</td>\n",
       "      <td>I was a-shovelling golden treasure out of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dream</td>\n",
       "      <td>15</td>\n",
       "      <td>The fatal Phryne</td>\n",
       "      <td>Philips, F. C.</td>\n",
       "      <td>He felt that he was looking on upon the scene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dream</td>\n",
       "      <td>16</td>\n",
       "      <td>The Crock of Gold</td>\n",
       "      <td>James Stephens</td>\n",
       "      <td>I dreamt I was a - working in my garden , hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dream</td>\n",
       "      <td>17</td>\n",
       "      <td>Samuel Boyd of Catchpole Square : a mystery</td>\n",
       "      <td>Farjeon, B. L.</td>\n",
       "      <td>' Don't forget your promise , ' he said . ' Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dream</td>\n",
       "      <td>18</td>\n",
       "      <td>The king who never died; tales of King Arthur</td>\n",
       "      <td>Senior, Dorothy</td>\n",
       "      <td>his kingdom was invaded by grifﬁns and serpent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dream</td>\n",
       "      <td>19</td>\n",
       "      <td>The king who never died; tales of King Arthur</td>\n",
       "      <td>Senior, Dorothy</td>\n",
       "      <td>out of the West came ﬂying a great dragon with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dream</td>\n",
       "      <td>20</td>\n",
       "      <td>The king who never died; tales of King Arthur</td>\n",
       "      <td>Senior, Dorothy</td>\n",
       "      <td>he and Sir Launcelot were sitting in one chair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dream</td>\n",
       "      <td>21</td>\n",
       "      <td>The king who never died; tales of King Arthur</td>\n",
       "      <td>Senior, Dorothy</td>\n",
       "      <td>He thought that, dressed in his royal robes, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dream</td>\n",
       "      <td>22</td>\n",
       "      <td>The Hall of Chavenlay; a winter's tale of 1649</td>\n",
       "      <td>Curling, Henry</td>\n",
       "      <td>a figure walked into my room, and up to my bed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dream</td>\n",
       "      <td>23</td>\n",
       "      <td>The Hall of Chavenlay; a winter's tale of 1649</td>\n",
       "      <td>Curling, Henry</td>\n",
       "      <td>I thought that a head without a body, was all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dream</td>\n",
       "      <td>24</td>\n",
       "      <td>The heavenly twins</td>\n",
       "      <td>Grand, Madame Sarah</td>\n",
       "      <td>she saw a semblance , the semblance of a man ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dream</td>\n",
       "      <td>25</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>I saw, a fair creature exactly like you in dre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dream</td>\n",
       "      <td>26</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>she had perpetrated some great wrong, and that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dream</td>\n",
       "      <td>27</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>thee were walking in the meadow, and that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dream</td>\n",
       "      <td>28</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>I was a little girl, out all alone on a wild m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dream</td>\n",
       "      <td>29</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>my Guardian Angel stood before my bed in the ﬁ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dream</td>\n",
       "      <td>30</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>he found himself wandering through a countless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dream</td>\n",
       "      <td>31</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>He saw a dark ﬂood and a boat aﬂoat on it. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dream</td>\n",
       "      <td>32</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>She thought that it was broad poonday , and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dream</td>\n",
       "      <td>33</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>I was a guest at the board of the commander - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Dream</td>\n",
       "      <td>34</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>I thought I was in a church crowded with peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Dream</td>\n",
       "      <td>35</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>the dim, dusky church she had visited, with it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Dream</td>\n",
       "      <td>36</td>\n",
       "      <td>tbd</td>\n",
       "      <td>tbd</td>\n",
       "      <td>I was again at Treval, seated in the cedar-tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Dream</td>\n",
       "      <td>37</td>\n",
       "      <td>A Love Story</td>\n",
       "      <td>Temple, Henrietta</td>\n",
       "      <td>He had been walking in a garden with Henrietta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dream</td>\n",
       "      <td>38</td>\n",
       "      <td>The gap in the garden</td>\n",
       "      <td>Wathen-Bartlett, Vanda</td>\n",
       "      <td>Her gaze followed down the fall of precipice t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Dream</td>\n",
       "      <td>39</td>\n",
       "      <td>Maurice Dering: or, The quadrilateral</td>\n",
       "      <td>Lawrence, George A.</td>\n",
       "      <td>we were standing together, just about this hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Dream</td>\n",
       "      <td>40</td>\n",
       "      <td>The Haven Under The Hill</td>\n",
       "      <td>Linskill, Mary</td>\n",
       "      <td>There was a vast desert plain, and I was wande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Dream</td>\n",
       "      <td>41</td>\n",
       "      <td>The Haven Under The Hill</td>\n",
       "      <td>Linskill, Mary</td>\n",
       "      <td>I had seemed to myself to be flying, flying ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Dream</td>\n",
       "      <td>42</td>\n",
       "      <td>The Steward</td>\n",
       "      <td>Cockton, Henry</td>\n",
       "      <td>Jane had denounced him, and then the whole pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dream</td>\n",
       "      <td>43</td>\n",
       "      <td>Falkenburg. A tale of the Rhine.</td>\n",
       "      <td>Murray, Hamilton</td>\n",
       "      <td>I was at home, and that a fairy brought to me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Dream</td>\n",
       "      <td>44</td>\n",
       "      <td>The School For Fathers</td>\n",
       "      <td>Gwynne, Talbot</td>\n",
       "      <td>she was in a wood : under the dark trees , and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Dream</td>\n",
       "      <td>45</td>\n",
       "      <td>High spirits : being certain stories written i...</td>\n",
       "      <td>Payn, James.</td>\n",
       "      <td>Betsey Prig appeared to me. She was driving me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Dream</td>\n",
       "      <td>46</td>\n",
       "      <td>Ellen Middleton : a tale</td>\n",
       "      <td>Fullerton, Georgiana, Lady</td>\n",
       "      <td>I was in church , and that every thing was pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Dream</td>\n",
       "      <td>47</td>\n",
       "      <td>The Old Commodore</td>\n",
       "      <td>Howard, Edward</td>\n",
       "      <td>the bed and the room used to seem as if they w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Dream</td>\n",
       "      <td>48</td>\n",
       "      <td>William Allair; or, Running away to sea</td>\n",
       "      <td>Wood, Henry, Mrs.</td>\n",
       "      <td>Once he fancied that he was back again; his mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Dream</td>\n",
       "      <td>49</td>\n",
       "      <td>William Allair; or, Running away to sea</td>\n",
       "      <td>Wood, Henry, Mrs.</td>\n",
       "      <td>he was at home at Whittermead; that it was one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Dream</td>\n",
       "      <td>50</td>\n",
       "      <td>Not easily jealous</td>\n",
       "      <td>Hardy, Iza Duffus</td>\n",
       "      <td>He saw a train whirl out of the station with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Dream</td>\n",
       "      <td>51</td>\n",
       "      <td>The Red Court Farm</td>\n",
       "      <td>Wood, Henry, Mrs.</td>\n",
       "      <td>Mrs. Chester had departed, and that she was di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Dream</td>\n",
       "      <td>52</td>\n",
       "      <td>Not dead yet</td>\n",
       "      <td>Jeaffreson, J. C.</td>\n",
       "      <td>I thought that I was walking under the trees o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Dream</td>\n",
       "      <td>53</td>\n",
       "      <td>Not dead yet</td>\n",
       "      <td>Jeaffreson, J. C.</td>\n",
       "      <td>I suddenly became aware that my cousin was dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dream</td>\n",
       "      <td>54</td>\n",
       "      <td>Not dead yet</td>\n",
       "      <td>Jeaffreson, J. C.</td>\n",
       "      <td>she saw a group of beautiful children at her f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Dream</td>\n",
       "      <td>55</td>\n",
       "      <td>Miracles of Anti-Christ</td>\n",
       "      <td>Lagerlöf, Selma</td>\n",
       "      <td>in the harbor of Catania lay a ship loaded wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Dream</td>\n",
       "      <td>56</td>\n",
       "      <td>Miracles of Anti-Christ</td>\n",
       "      <td>Lagerlöf, Selma</td>\n",
       "      <td>I saw the Christchild before me in his crown a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Dream</td>\n",
       "      <td>57</td>\n",
       "      <td>Stella Fregelius, a tale of three destinies</td>\n",
       "      <td>Haggard, H. Rider</td>\n",
       "      <td>Morris looked up arousing himself to listen, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Dream</td>\n",
       "      <td>58</td>\n",
       "      <td>A romance of two worlds</td>\n",
       "      <td>Corelli, Marie</td>\n",
       "      <td>I thought I saw a circular spacious garden in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Dream</td>\n",
       "      <td>59</td>\n",
       "      <td>Outsiders--and in</td>\n",
       "      <td>Ayscough, John</td>\n",
       "      <td>she saw the nightly performance, the naphtha l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  id                                             author  \\\n",
       "0   Dream   0                                                tbd   \n",
       "1   Dream   1                                          The Idiot   \n",
       "2   Dream   2                                      War and Peace   \n",
       "3   Dream   3                                      War and Peace   \n",
       "4   Dream   4                                                tbd   \n",
       "5   Dream   5                                                tbd   \n",
       "6   Dream   6                                     Rose o'the sea   \n",
       "7   Dream   7                                         Nightshade   \n",
       "8   Dream   8                                             Yonder   \n",
       "9   Dream   9                                         Blind Eyes   \n",
       "10  Dream  10                                 The White Causeway   \n",
       "11  Dream  11  Dearlove : the history of her summer's makebel...   \n",
       "12  Dream  12                              For Charles the Rover   \n",
       "13  Dream  13                                          Entrapped   \n",
       "14  Dream  14                                     Uncle Polperro   \n",
       "15  Dream  15                                   The fatal Phryne   \n",
       "16  Dream  16                                  The Crock of Gold   \n",
       "17  Dream  17        Samuel Boyd of Catchpole Square : a mystery   \n",
       "18  Dream  18      The king who never died; tales of King Arthur   \n",
       "19  Dream  19      The king who never died; tales of King Arthur   \n",
       "20  Dream  20      The king who never died; tales of King Arthur   \n",
       "21  Dream  21      The king who never died; tales of King Arthur   \n",
       "22  Dream  22     The Hall of Chavenlay; a winter's tale of 1649   \n",
       "23  Dream  23     The Hall of Chavenlay; a winter's tale of 1649   \n",
       "24  Dream  24                                 The heavenly twins   \n",
       "25  Dream  25                                                tbd   \n",
       "26  Dream  26                                                tbd   \n",
       "27  Dream  27                                                tbd   \n",
       "28  Dream  28                                                tbd   \n",
       "29  Dream  29                                                tbd   \n",
       "30  Dream  30                                                tbd   \n",
       "31  Dream  31                                                tbd   \n",
       "32  Dream  32                                                tbd   \n",
       "33  Dream  33                                                tbd   \n",
       "34  Dream  34                                                tbd   \n",
       "35  Dream  35                                                tbd   \n",
       "36  Dream  36                                                tbd   \n",
       "37  Dream  37                                       A Love Story   \n",
       "38  Dream  38                              The gap in the garden   \n",
       "39  Dream  39              Maurice Dering: or, The quadrilateral   \n",
       "40  Dream  40                           The Haven Under The Hill   \n",
       "41  Dream  41                           The Haven Under The Hill   \n",
       "42  Dream  42                                        The Steward   \n",
       "43  Dream  43                   Falkenburg. A tale of the Rhine.   \n",
       "44  Dream  44                             The School For Fathers   \n",
       "45  Dream  45  High spirits : being certain stories written i...   \n",
       "46  Dream  46                           Ellen Middleton : a tale   \n",
       "47  Dream  47                                  The Old Commodore   \n",
       "48  Dream  48            William Allair; or, Running away to sea   \n",
       "49  Dream  49            William Allair; or, Running away to sea   \n",
       "50  Dream  50                                 Not easily jealous   \n",
       "51  Dream  51                                The Red Court Farm    \n",
       "52  Dream  52                                       Not dead yet   \n",
       "53  Dream  53                                       Not dead yet   \n",
       "54  Dream  54                                       Not dead yet   \n",
       "55  Dream  55                            Miracles of Anti-Christ   \n",
       "56  Dream  56                            Miracles of Anti-Christ   \n",
       "57  Dream  57        Stella Fregelius, a tale of three destinies   \n",
       "58  Dream  58                            A romance of two worlds   \n",
       "59  Dream  59                                  Outsiders--and in   \n",
       "\n",
       "                                        title  \\\n",
       "0                                         tbd   \n",
       "1                          Dostoevsky, Fyodor   \n",
       "2                                Tolstoy, Leo   \n",
       "3                                Tolstoy, Leo   \n",
       "4                                         tbd   \n",
       "5                                         tbd   \n",
       "6   Evans, Marguerite Florence Jervis Barclay   \n",
       "7                                Gwynne, Paul   \n",
       "8                                 Young, E.H.   \n",
       "9                          Peterson, Margaret   \n",
       "10                        Moore, F. Frankfort   \n",
       "11                          Campbell, Frances   \n",
       "12                    Knowles, Mabel Winifred   \n",
       "13                            Diehl, Alice M.   \n",
       "14                       Courlander, Alphonse   \n",
       "15                             Philips, F. C.   \n",
       "16                             James Stephens   \n",
       "17                            Farjeon, B. L.    \n",
       "18                            Senior, Dorothy   \n",
       "19                            Senior, Dorothy   \n",
       "20                            Senior, Dorothy   \n",
       "21                            Senior, Dorothy   \n",
       "22                             Curling, Henry   \n",
       "23                             Curling, Henry   \n",
       "24                        Grand, Madame Sarah   \n",
       "25                                        tbd   \n",
       "26                                        tbd   \n",
       "27                                        tbd   \n",
       "28                                        tbd   \n",
       "29                                        tbd   \n",
       "30                                        tbd   \n",
       "31                                        tbd   \n",
       "32                                        tbd   \n",
       "33                                        tbd   \n",
       "34                                        tbd   \n",
       "35                                        tbd   \n",
       "36                                        tbd   \n",
       "37                          Temple, Henrietta   \n",
       "38                     Wathen-Bartlett, Vanda   \n",
       "39                        Lawrence, George A.   \n",
       "40                             Linskill, Mary   \n",
       "41                             Linskill, Mary   \n",
       "42                             Cockton, Henry   \n",
       "43                           Murray, Hamilton   \n",
       "44                             Gwynne, Talbot   \n",
       "45                               Payn, James.   \n",
       "46                 Fullerton, Georgiana, Lady   \n",
       "47                             Howard, Edward   \n",
       "48                          Wood, Henry, Mrs.   \n",
       "49                          Wood, Henry, Mrs.   \n",
       "50                          Hardy, Iza Duffus   \n",
       "51                          Wood, Henry, Mrs.   \n",
       "52                         Jeaffreson, J. C.    \n",
       "53                         Jeaffreson, J. C.    \n",
       "54                          Jeaffreson, J. C.   \n",
       "55                            Lagerlöf, Selma   \n",
       "56                            Lagerlöf, Selma   \n",
       "57                          Haggard, H. Rider   \n",
       "58                             Corelli, Marie   \n",
       "59                             Ayscough, John   \n",
       "\n",
       "                                                 text  \n",
       "0   I was in Italy, and awoke (or seemed to awake)...  \n",
       "1   I was in some room, not my own. It was a large...  \n",
       "2   I. A. Bazdei'ew is in my house and I want to e...  \n",
       "3   I saw as if in my house in Moscow, Bazdeiew en...  \n",
       "4   some English people had come into the hotel wh...  \n",
       "5   It was a great Piazza, as I thought ; anchored...  \n",
       "6   I was climbing great cliffs, like I used to at...  \n",
       "7   I remember vividly every detail of what I saw,...  \n",
       "8   I was walking on a green path and I met a man ...  \n",
       "9   Ted was dead, she fancied: his white, set face...  \n",
       "10  I found myself wandering over a house , and lo...  \n",
       "11  we were standing on the shore, and your ship w...  \n",
       "12  I thought myself once again a bride groom with...  \n",
       "13  She was wandering in an English hayfield, unde...  \n",
       "14  I was a-shovelling golden treasure out of the ...  \n",
       "15  He felt that he was looking on upon the scene ...  \n",
       "16  I dreamt I was a - working in my garden , hard...  \n",
       "17  ' Don't forget your promise , ' he said . ' Lo...  \n",
       "18  his kingdom was invaded by grifﬁns and serpent...  \n",
       "19  out of the West came ﬂying a great dragon with...  \n",
       "20  he and Sir Launcelot were sitting in one chair...  \n",
       "21  He thought that, dressed in his royal robes, h...  \n",
       "22  a figure walked into my room, and up to my bed...  \n",
       "23  I thought that a head without a body, was all ...  \n",
       "24  she saw a semblance , the semblance of a man ,...  \n",
       "25  I saw, a fair creature exactly like you in dre...  \n",
       "26  she had perpetrated some great wrong, and that...  \n",
       "27  thee were walking in the meadow, and that the ...  \n",
       "28  I was a little girl, out all alone on a wild m...  \n",
       "29  my Guardian Angel stood before my bed in the ﬁ...  \n",
       "30  he found himself wandering through a countless...  \n",
       "31  He saw a dark ﬂood and a boat aﬂoat on it. The...  \n",
       "32  She thought that it was broad poonday , and th...  \n",
       "33  I was a guest at the board of the commander - ...  \n",
       "34  I thought I was in a church crowded with peopl...  \n",
       "35  the dim, dusky church she had visited, with it...  \n",
       "36  I was again at Treval, seated in the cedar-tre...  \n",
       "37  He had been walking in a garden with Henrietta...  \n",
       "38  Her gaze followed down the fall of precipice t...  \n",
       "39  we were standing together, just about this hou...  \n",
       "40  There was a vast desert plain, and I was wande...  \n",
       "41  I had seemed to myself to be flying, flying ov...  \n",
       "42  Jane had denounced him, and then the whole pro...  \n",
       "43  I was at home, and that a fairy brought to me ...  \n",
       "44  she was in a wood : under the dark trees , and...  \n",
       "45  Betsey Prig appeared to me. She was driving me...  \n",
       "46  I was in church , and that every thing was pre...  \n",
       "47  the bed and the room used to seem as if they w...  \n",
       "48  Once he fancied that he was back again; his mo...  \n",
       "49  he was at home at Whittermead; that it was one...  \n",
       "50  He saw a train whirl out of the station with t...  \n",
       "51  Mrs. Chester had departed, and that she was di...  \n",
       "52  I thought that I was walking under the trees o...  \n",
       "53  I suddenly became aware that my cousin was dea...  \n",
       "54  she saw a group of beautiful children at her f...  \n",
       "55  in the harbor of Catania lay a ship loaded wit...  \n",
       "56  I saw the Christchild before me in his crown a...  \n",
       "57  Morris looked up arousing himself to listen, a...  \n",
       "58  I thought I saw a circular spacious garden in ...  \n",
       "59  she saw the nightly performance, the naphtha l...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dreams = pd.read_csv('validation_dreams.txt', sep='\\t')\n",
    "validation_dreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dreams['split'] = validation_dreams['text'].apply(lambda x : nltk.word_tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dreams['counts'] =validation_dreams.split.apply(lambda x: Counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dreams = validation_dreams.loc[:,['split','counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dreamsDF = pd.DataFrame.from_records(validation_dreams.counts.values.tolist()).stack().reset_index().rename(columns={'level_0':'page','level_1':'tokens',0:'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>tokens</th>\n",
       "      <th>counts</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>was</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>3.0</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>italy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>7.0</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>59</td>\n",
       "      <td>elephant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>59</td>\n",
       "      <td>three-legged</td>\n",
       "      <td>1.0</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6579</th>\n",
       "      <td>59</td>\n",
       "      <td>tub</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6580</th>\n",
       "      <td>59</td>\n",
       "      <td>only—monsieur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6581</th>\n",
       "      <td>59</td>\n",
       "      <td>cage</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6582 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      page         tokens  counts  pos\n",
       "0        0              i     4.0   NN\n",
       "1        0            was     1.0  VBD\n",
       "2        0             in     3.0   IN\n",
       "3        0          italy     1.0   NN\n",
       "4        0              ,     7.0    ,\n",
       "...    ...            ...     ...  ...\n",
       "6577    59       elephant     1.0   NN\n",
       "6578    59   three-legged     1.0   JJ\n",
       "6579    59            tub     1.0   NN\n",
       "6580    59  only—monsieur     1.0   NN\n",
       "6581    59           cage     1.0   NN\n",
       "\n",
       "[6582 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dreamsDF['pos'] = validation_dreamsDF['tokens'].apply(lambda x : (nltk.pos_tag([x]))[0][1])\n",
    "validation_dreamsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_all_data():\n",
    "    data=[]\n",
    "    fict_folder= \"/home/abc/Berkeley/CompHum/Project/HathiTrust/fiction\"\n",
    "    get_fiction_data(data, fict_folder, 1, 'test') #Get 50 books\n",
    "    data.extend(get_data(validation_dreamsDF, 1, 'avg'))\n",
    "    #data.extend(get_data(fiction_data,0))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for unigram_counts, label in data:\n",
    "        X.append(unigram_counts)\n",
    "        Y.append(label)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "#Read Validation Data\n",
    "X_val, Y_val=get_val_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 116\n"
     ]
    }
   ],
   "source": [
    "print(Y_val.count(1), Y_val.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def predict(trainX, trainY, clf, feature_functions):\n",
    "\n",
    "    \"\"\" This function evaluates a list of feature functions on the training/dev data arguments \"\"\"\n",
    "    \n",
    "    trainX_feat=build_features(trainX, feature_functions)\n",
    "    # just create vocabulary from features in *training* data.\n",
    "    feature_vocab=create_vocab(trainX_feat, top_n=1000)\n",
    "    \n",
    "    trainX_ids=features_to_ids(trainX_feat, feature_vocab)\n",
    "\n",
    "    accuracy = clf.score(trainX_ids, trainY)\n",
    "    print(\"Accuracy: %.3f\" % accuracy)\n",
    "    y_pred = clf.predict(trainX_ids)\n",
    "    F1 = f1_score(trainY, y_pred)\n",
    "    print(\"F1 score:\",f1_score(trainY, y_pred))\n",
    "    return accuracy, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.40s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922\n",
      "F1 score: 0.6923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.17s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925\n",
      "F1 score: 0.7407407407407408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.26it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.804\n",
      "F1 score: 0.5137614678899083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.16it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.864\n",
      "F1 score: 0.6732673267326732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.19s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.902\n",
      "F1 score: 0.735042735042735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.58s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.876\n",
      "F1 score: 0.5436893203883496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.10s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.859\n",
      "F1 score: 0.6285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.55s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.917\n",
      "F1 score: 0.608695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.67it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754\n",
      "F1 score: 0.5203252032520326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.58s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.902\n",
      "F1 score: 0.5242718446601942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.07s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.869\n",
      "F1 score: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.06s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.859\n",
      "F1 score: 0.5473684210526316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.00it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868\n",
      "F1 score: 0.7027027027027027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.47s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.937\n",
      "F1 score: 0.6346153846153847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.28it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.804\n",
      "F1 score: 0.5671641791044775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.42s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.917\n",
      "F1 score: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.21it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854\n",
      "F1 score: 0.6019417475728156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.05s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.886\n",
      "F1 score: 0.6346153846153847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.15s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.913\n",
      "F1 score: 0.7378640776699028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.08s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.879\n",
      "F1 score: 0.6285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.26it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.880\n",
      "F1 score: 0.7058823529411764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.30it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872\n",
      "F1 score: 0.6990291262135923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.02it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "F1 score: 0.6476190476190475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.11it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.888\n",
      "F1 score: 0.6942148760330578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.04it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790\n",
      "F1 score: 0.49557522123893805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.30it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.812\n",
      "F1 score: 0.6050420168067226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.21s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.858\n",
      "F1 score: 0.5321100917431193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.07it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856\n",
      "F1 score: 0.574468085106383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.40it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850\n",
      "F1 score: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.16s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.879\n",
      "F1 score: 0.6379310344827587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.43s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.874\n",
      "F1 score: 0.5531914893617021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.03it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n",
      "F1 score: 0.47457627118644075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.28it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872\n",
      "F1 score: 0.6990291262135923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.11it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854\n",
      "F1 score: 0.5882352941176471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.02s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846\n",
      "F1 score: 0.5391304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.12it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.876\n",
      "F1 score: 0.6804123711340206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.24s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.903\n",
      "F1 score: 0.7238095238095237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.29s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.916\n",
      "F1 score: 0.673469387755102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.03it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856\n",
      "F1 score: 0.5210084033613446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.20s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.933\n",
      "F1 score: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.77s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.890\n",
      "F1 score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.15s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.914\n",
      "F1 score: 0.7478260869565218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.32s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.903\n",
      "F1 score: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.33s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.897\n",
      "F1 score: 0.6776859504132232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.07s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.863\n",
      "F1 score: 0.5631067961165049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.30s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872\n",
      "F1 score: 0.6119402985074627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.48s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.867\n",
      "F1 score: 0.5132743362831859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.01s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889\n",
      "F1 score: 0.6407766990291263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.12s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868\n",
      "F1 score: 0.5510204081632654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.33s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.900\n",
      "F1 score: 0.6990291262135923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.82s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.913\n",
      "F1 score: 0.5686274509803921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.22it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.861\n",
      "F1 score: 0.6336633663366336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.96s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.926\n",
      "F1 score: 0.673076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.25it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.840\n",
      "F1 score: 0.6551724137931035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.14it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.849\n",
      "F1 score: 0.48351648351648346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.13it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.892\n",
      "F1 score: 0.6938775510204083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.31s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.849\n",
      "F1 score: 0.4077669902912621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.29s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.903\n",
      "F1 score: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.76it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856\n",
      "F1 score: 0.7200000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.19s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922\n",
      "F1 score: 0.7796610169491527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.60it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784\n",
      "F1 score: 0.6122448979591837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.82s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.901\n",
      "F1 score: 0.5631067961165049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.21s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.843\n",
      "F1 score: 0.507936507936508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.07it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776\n",
      "F1 score: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.79it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.787\n",
      "F1 score: 0.5892857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.00s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n",
      "F1 score: 0.4444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.18s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.877\n",
      "F1 score: 0.6990291262135923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.26it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.812\n",
      "F1 score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.06it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.863\n",
      "F1 score: 0.5894736842105264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.34s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872\n",
      "F1 score: 0.5688073394495414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.31s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.871\n",
      "F1 score: 0.5434782608695653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.38s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.941\n",
      "F1 score: 0.6105263157894737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.50it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.758\n",
      "F1 score: 0.5321100917431193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.14it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.849\n",
      "F1 score: 0.5333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.36it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850\n",
      "F1 score: 0.6326530612244898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.66it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770\n",
      "F1 score: 0.5789473684210527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.22s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.841\n",
      "F1 score: 0.5039370078740157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.40it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862\n",
      "F1 score: 0.6930693069306931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.23it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.811\n",
      "F1 score: 0.5233644859813084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.04s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856\n",
      "F1 score: 0.3818181818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.01s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.878\n",
      "F1 score: 0.6610169491525424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.24it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.871\n",
      "F1 score: 0.6542056074766355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.18it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.878\n",
      "F1 score: 0.6874999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.28it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.813\n",
      "F1 score: 0.5490196078431373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.07s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.844\n",
      "F1 score: 0.48333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.45it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.886\n",
      "F1 score: 0.766355140186916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.57s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.869\n",
      "F1 score: 0.5811965811965812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.51s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.853\n",
      "F1 score: 0.5050505050505051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.72s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924\n",
      "F1 score: 0.45238095238095233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.29it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.826\n",
      "F1 score: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.25s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.865\n",
      "F1 score: 0.5142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.01s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.818\n",
      "F1 score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.22s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924\n",
      "F1 score: 0.7704918032786884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.06it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.864\n",
      "F1 score: 0.6019417475728156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.23it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.804\n",
      "F1 score: 0.5046728971962617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.48s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.886\n",
      "F1 score: 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.08s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.874\n",
      "F1 score: 0.5849056603773585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.09s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.884\n",
      "F1 score: 0.6285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.36s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.910\n",
      "F1 score: 0.6262626262626263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.901\n",
      "F1 score: 0.6542056074766355\n"
     ]
    }
   ],
   "source": [
    "acc_all=[]\n",
    "f1_all=[]\n",
    "for i in range(100):\n",
    "    X_val, Y_val=get_val_all_data()\n",
    "    features=[unigram_feature, pos_feature, liwc_feature]\n",
    "    acc, f1 = predict(X_val, Y_val, clf, features)\n",
    "    acc_all.append(acc)\n",
    "    f1_all.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy on validation set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8662172432364713"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Average accuracy on validation set\")\n",
    "sum(acc_all)/len(acc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score on validation set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6010240154212846"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Average F1 score on validation set\")\n",
    "sum(f1_all)/len(f1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt \n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_confidence_intervals(predictions, truth, confidence_level=0.95):\n",
    "    correct=[]\n",
    "    for pred, gold in zip(predictions, truth):\n",
    "        correct.append(int(pred==gold))\n",
    "        \n",
    "    success_rate=np.mean(correct)\n",
    "\n",
    "    # two-tailed test\n",
    "    critical_value=(1-confidence_level)/2\n",
    "    # ppf finds z such that p(X < z) = critical_value\n",
    "    z_alpha=-1*norm.ppf(critical_value)\n",
    "    \n",
    "    # the standard error is the square root of the variance/sample size\n",
    "    # the variance for a binomial test is p*(1-p)\n",
    "    standard_error=sqrt((success_rate*(1-success_rate))/len(correct))\n",
    "\n",
    "    lower=success_rate-z_alpha*standard_error\n",
    "    upper=success_rate+z_alpha*standard_error\n",
    "    print(\"%.3f, %s%% Confidence interval: [%.3f,%.3f]\" % (success_rate, confidence_level*100, lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813, 95.0% Confidence interval: [0.777,0.850]\n"
     ]
    }
   ],
   "source": [
    "binomial_confidence_intervals(preds, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 48, 127, 81, 80, 60, 191, 105, 135, 75]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(range(1, 200), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-504-0ba5956153ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-464-7e0043bf8de5>\u001b[0m in \u001b[0;36mget_all_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfict_folder\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"HathiTrust/fiction\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mget_fiction_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfict_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Get 100 books\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdream_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#data.extend(get_data(fiction_data,0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-463-1e7549598cd2>\u001b[0m in \u001b[0;36mget_fiction_data\u001b[0;34m(data, fict_folder, total_books, train_test)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mthe_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-462-ed84f71d745f>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(df, label, constant)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Filter out the stop_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstop_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Rescale all the tokens to 200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescaleCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-462-ed84f71d745f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Filter out the stop_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstop_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Rescale all the tokens to 200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescaleCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-74c92f83bb5e>\u001b[0m in \u001b[0;36mstop_filter\u001b[0;34m(word, stopwords)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# no stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, Y=get_all_data()\n",
    "trainX, devX, trainY, devY = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
